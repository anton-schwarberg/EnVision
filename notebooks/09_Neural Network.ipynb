{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09d24b0ddf9f0fa",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa5ad06-c80a-4e46-8087-7b9602ea359e",
   "metadata": {},
   "source": [
    "In this notebook, a neural network is trained. Neural networks are powerful models capable of capturing complex, non-linear relationships in the data. This model consists of two hidden layers with ReLU activation, dropout for regularization, and a sigmoid output layer for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fdd5d77964a5814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:51:48.397687Z",
     "start_time": "2024-05-15T17:51:44.771938Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as python_random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c9451f0a0556e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:51:49.274154Z",
     "start_time": "2024-05-15T17:51:48.398885Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>household_size</th>\n",
       "      <th>occupation_status</th>\n",
       "      <th>income</th>\n",
       "      <th>house_type</th>\n",
       "      <th>house_age</th>\n",
       "      <th>house_size</th>\n",
       "      <th>location</th>\n",
       "      <th>energy_bill</th>\n",
       "      <th>...</th>\n",
       "      <th>knowledge_energy</th>\n",
       "      <th>energy_awareness</th>\n",
       "      <th>attitude_energy_reduction</th>\n",
       "      <th>investment_willingness</th>\n",
       "      <th>belief_climate_change</th>\n",
       "      <th>financial_awareness</th>\n",
       "      <th>perceived_efficiency</th>\n",
       "      <th>environment_concern</th>\n",
       "      <th>previous_renovations</th>\n",
       "      <th>booked_energy_consultation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>20108</td>\n",
       "      <td>Multi-family House</td>\n",
       "      <td>2020</td>\n",
       "      <td>120</td>\n",
       "      <td>Rural</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>Employed</td>\n",
       "      <td>53000</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2020</td>\n",
       "      <td>400</td>\n",
       "      <td>Urban</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>Employed</td>\n",
       "      <td>86352</td>\n",
       "      <td>Detached</td>\n",
       "      <td>1953</td>\n",
       "      <td>253</td>\n",
       "      <td>Urban</td>\n",
       "      <td>165</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Employed</td>\n",
       "      <td>27633</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2018</td>\n",
       "      <td>108</td>\n",
       "      <td>Urban</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Employed</td>\n",
       "      <td>25011</td>\n",
       "      <td>Detached</td>\n",
       "      <td>2020</td>\n",
       "      <td>110</td>\n",
       "      <td>Urban</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  household_size occupation_status  income          house_type  \\\n",
       "0   26    Male               1        Unemployed   20108  Multi-family House   \n",
       "1   28  Female               3          Employed   53000            Detached   \n",
       "2   52    Male               2          Employed   86352            Detached   \n",
       "3   17   Other               1          Employed   27633            Detached   \n",
       "4   20    Male               1          Employed   25011            Detached   \n",
       "\n",
       "   house_age  house_size location  energy_bill  ... knowledge_energy  \\\n",
       "0       2020         120    Rural          103  ...                4   \n",
       "1       2020         400    Urban          170  ...                2   \n",
       "2       1953         253    Urban          165  ...                2   \n",
       "3       2018         108    Urban          102  ...                4   \n",
       "4       2020         110    Urban          106  ...                4   \n",
       "\n",
       "   energy_awareness  attitude_energy_reduction  investment_willingness  \\\n",
       "0                 4                          2                       1   \n",
       "1                 4                          5                       3   \n",
       "2                 2                          3                       4   \n",
       "3                 4                          2                       1   \n",
       "4                 4                          2                       1   \n",
       "\n",
       "   belief_climate_change financial_awareness perceived_efficiency  \\\n",
       "0                    Yes                  No                    1   \n",
       "1                    Yes                  No                    2   \n",
       "2                    Yes                  No                    2   \n",
       "3                    Yes                  No                    4   \n",
       "4                    Yes                  No                    1   \n",
       "\n",
       "   environment_concern  previous_renovations  booked_energy_consultation  \n",
       "0                    2                    10                       False  \n",
       "1                    5                     1                       False  \n",
       "2                    1                     7                        True  \n",
       "3                    2                     7                       False  \n",
       "4                    2                     9                       False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('combined_data_binary.xlsx', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33db8313c845805f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:51:49.274459Z",
     "start_time": "2024-05-15T17:51:49.271166Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def reset_random_seeds():\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "reset_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b5b2e22a47d32b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:51:49.287781Z",
     "start_time": "2024-05-15T17:51:49.275422Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop('booked_energy_consultation', axis=1)\n",
    "y = df['booked_energy_consultation']\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# One-hot encode the categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "categorical_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "categorical_encoded_df = pd.DataFrame(categorical_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "X = pd.concat([X[numerical_cols].reset_index(drop=True), categorical_encoded_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a24ae97a1c3fd03",
   "metadata": {},
   "source": [
    "### Splitting the data into test and training set, training set 70%, test set 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb5234d336f890a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:51:49.288197Z",
     "start_time": "2024-05-15T17:51:49.285022Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274427b0d85f6955",
   "metadata": {},
   "source": [
    "### Scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f83935ce3da3c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:51:49.292542Z",
     "start_time": "2024-05-15T17:51:49.289404Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371d74b8b12c745e",
   "metadata": {},
   "source": [
    "## Building the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e46e9ba0228f2d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:51:49.330709Z",
     "start_time": "2024-05-15T17:51:49.293717Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(X_train.shape[1],)), \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09500fe1618c9f",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c64de0a99c970810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:51:49.362326Z",
     "start_time": "2024-05-15T17:51:49.326134Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',  # Change loss if it's a multi-class classification\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183afb6b0dc7dd0",
   "metadata": {},
   "source": [
    "### Training the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b4c507a2a960c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:52:00.241849Z",
     "start_time": "2024-05-15T17:51:49.333713Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5281 - loss: 726.2455 - precision: 0.3504 - recall: 0.5151 - val_accuracy: 0.7733 - val_loss: 17.5879 - val_precision: 0.9380 - val_recall: 0.3447\n",
      "Epoch 2/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.7431 - loss: 85.0393 - precision: 0.6013 - recall: 0.6922 - val_accuracy: 0.9038 - val_loss: 15.2330 - val_precision: 0.8655 - val_recall: 0.8433\n",
      "Epoch 3/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8323 - loss: 41.2269 - precision: 0.7410 - recall: 0.7710 - val_accuracy: 0.9010 - val_loss: 16.6510 - val_precision: 0.8365 - val_recall: 0.8746\n",
      "Epoch 4/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8496 - loss: 31.0726 - precision: 0.7712 - recall: 0.7908 - val_accuracy: 0.8886 - val_loss: 37.1965 - val_precision: 0.7799 - val_recall: 0.9288\n",
      "Epoch 5/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.8402 - loss: 30.5581 - precision: 0.7533 - recall: 0.7813 - val_accuracy: 0.9067 - val_loss: 12.2175 - val_precision: 0.8543 - val_recall: 0.8689\n",
      "Epoch 6/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8643 - loss: 20.4447 - precision: 0.8024 - recall: 0.7918 - val_accuracy: 0.8924 - val_loss: 15.5423 - val_precision: 0.8005 - val_recall: 0.9031\n",
      "Epoch 7/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.8674 - loss: 15.3623 - precision: 0.7987 - recall: 0.8045 - val_accuracy: 0.8886 - val_loss: 14.4184 - val_precision: 0.7868 - val_recall: 0.9145\n",
      "Epoch 8/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8510 - loss: 15.1100 - precision: 0.7783 - recall: 0.7971 - val_accuracy: 0.8486 - val_loss: 28.7207 - val_precision: 0.7000 - val_recall: 0.9573\n",
      "Epoch 9/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7938 - loss: 33.7649 - precision: 0.6667 - recall: 0.7741 - val_accuracy: 0.8933 - val_loss: 10.2098 - val_precision: 0.8187 - val_recall: 0.8746\n",
      "Epoch 10/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.8566 - loss: 13.0430 - precision: 0.7781 - recall: 0.7985 - val_accuracy: 0.9086 - val_loss: 6.9994 - val_precision: 0.8972 - val_recall: 0.8205\n",
      "Epoch 11/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.8704 - loss: 9.8772 - precision: 0.8224 - recall: 0.7819 - val_accuracy: 0.8914 - val_loss: 5.1545 - val_precision: 0.7985 - val_recall: 0.9031\n",
      "Epoch 12/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.8710 - loss: 5.9668 - precision: 0.8051 - recall: 0.8059 - val_accuracy: 0.8933 - val_loss: 4.6382 - val_precision: 0.8072 - val_recall: 0.8946\n",
      "Epoch 13/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.8410 - loss: 8.6828 - precision: 0.7667 - recall: 0.7864 - val_accuracy: 0.8924 - val_loss: 4.8890 - val_precision: 0.8051 - val_recall: 0.8946\n",
      "Epoch 14/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.8666 - loss: 6.7005 - precision: 0.7935 - recall: 0.8141 - val_accuracy: 0.8857 - val_loss: 2.3144 - val_precision: 0.9231 - val_recall: 0.7179\n",
      "Epoch 15/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.8481 - loss: 6.5927 - precision: 0.7891 - recall: 0.7743 - val_accuracy: 0.8886 - val_loss: 7.8218 - val_precision: 0.7854 - val_recall: 0.9174\n",
      "Epoch 16/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8664 - loss: 4.8624 - precision: 0.7914 - recall: 0.8047 - val_accuracy: 0.8876 - val_loss: 6.6996 - val_precision: 0.7807 - val_recall: 0.9231\n",
      "Epoch 17/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.8506 - loss: 5.3790 - precision: 0.7774 - recall: 0.7977 - val_accuracy: 0.9048 - val_loss: 3.1142 - val_precision: 0.8617 - val_recall: 0.8519\n",
      "Epoch 18/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.8669 - loss: 4.4680 - precision: 0.8092 - recall: 0.7960 - val_accuracy: 0.9048 - val_loss: 2.2254 - val_precision: 0.8575 - val_recall: 0.8575\n",
      "Epoch 19/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.8639 - loss: 4.2210 - precision: 0.7940 - recall: 0.7985 - val_accuracy: 0.9029 - val_loss: 1.8238 - val_precision: 0.8694 - val_recall: 0.8348\n",
      "Epoch 20/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.8547 - loss: 4.2943 - precision: 0.7792 - recall: 0.7760 - val_accuracy: 0.9067 - val_loss: 3.0683 - val_precision: 0.8667 - val_recall: 0.8519\n",
      "Epoch 21/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.8618 - loss: 5.0878 - precision: 0.8213 - recall: 0.7713 - val_accuracy: 0.8838 - val_loss: 2.3061 - val_precision: 0.7694 - val_recall: 0.9316\n",
      "Epoch 22/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.8642 - loss: 2.3990 - precision: 0.7855 - recall: 0.8036 - val_accuracy: 0.8733 - val_loss: 2.6012 - val_precision: 0.7401 - val_recall: 0.9573\n",
      "Epoch 23/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.8360 - loss: 3.4272 - precision: 0.7461 - recall: 0.7914 - val_accuracy: 0.8971 - val_loss: 1.2736 - val_precision: 0.8156 - val_recall: 0.8946\n",
      "Epoch 24/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.8737 - loss: 1.7865 - precision: 0.8073 - recall: 0.8259 - val_accuracy: 0.8895 - val_loss: 2.8892 - val_precision: 0.7873 - val_recall: 0.9174\n",
      "Epoch 25/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.8611 - loss: 2.4212 - precision: 0.7922 - recall: 0.7992 - val_accuracy: 0.8648 - val_loss: 4.1395 - val_precision: 0.7359 - val_recall: 0.9288\n",
      "Epoch 26/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.8571 - loss: 2.7020 - precision: 0.7776 - recall: 0.8079 - val_accuracy: 0.9067 - val_loss: 0.9106 - val_precision: 0.8667 - val_recall: 0.8519\n",
      "Epoch 27/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.8550 - loss: 1.9233 - precision: 0.7809 - recall: 0.7802 - val_accuracy: 0.6676 - val_loss: 2.1641 - val_precision: 0.6667 - val_recall: 0.0114\n",
      "Epoch 28/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.8639 - loss: 1.3860 - precision: 0.8027 - recall: 0.7916 - val_accuracy: 0.9105 - val_loss: 0.4717 - val_precision: 0.9028 - val_recall: 0.8205\n",
      "Epoch 29/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8512 - loss: 1.4010 - precision: 0.7661 - recall: 0.8002 - val_accuracy: 0.8790 - val_loss: 2.3591 - val_precision: 0.7581 - val_recall: 0.9373\n",
      "Epoch 30/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.8717 - loss: 1.2401 - precision: 0.8095 - recall: 0.8149 - val_accuracy: 0.8981 - val_loss: 0.4879 - val_precision: 0.8228 - val_recall: 0.8860\n",
      "Epoch 31/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.8749 - loss: 0.7152 - precision: 0.8216 - recall: 0.8029 - val_accuracy: 0.8905 - val_loss: 0.9299 - val_precision: 0.7995 - val_recall: 0.8974\n",
      "Epoch 32/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.8741 - loss: 1.0006 - precision: 0.8078 - recall: 0.8136 - val_accuracy: 0.8914 - val_loss: 1.0881 - val_precision: 0.7912 - val_recall: 0.9174\n",
      "Epoch 33/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.8747 - loss: 1.0282 - precision: 0.8138 - recall: 0.8199 - val_accuracy: 0.9000 - val_loss: 0.4408 - val_precision: 0.8220 - val_recall: 0.8946\n",
      "Epoch 34/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.8845 - loss: 0.5412 - precision: 0.8218 - recall: 0.8411 - val_accuracy: 0.9133 - val_loss: 0.3558 - val_precision: 0.9221 - val_recall: 0.8091\n",
      "Epoch 35/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.8554 - loss: 0.5825 - precision: 0.7950 - recall: 0.7844 - val_accuracy: 0.8914 - val_loss: 0.6821 - val_precision: 0.8000 - val_recall: 0.9003\n",
      "Epoch 36/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.8804 - loss: 0.4701 - precision: 0.8253 - recall: 0.8199 - val_accuracy: 0.9000 - val_loss: 0.4088 - val_precision: 0.8398 - val_recall: 0.8661\n",
      "Epoch 37/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.8850 - loss: 0.4307 - precision: 0.8317 - recall: 0.8295 - val_accuracy: 0.6667 - val_loss: 0.6742 - val_precision: 1.0000 - val_recall: 0.0028\n",
      "Epoch 38/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8698 - loss: 0.5190 - precision: 0.8195 - recall: 0.7790 - val_accuracy: 0.8962 - val_loss: 0.3530 - val_precision: 0.8306 - val_recall: 0.8661\n",
      "Epoch 39/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9039 - loss: 0.2888 - precision: 0.8494 - recall: 0.8738 - val_accuracy: 0.9048 - val_loss: 0.2946 - val_precision: 0.8617 - val_recall: 0.8519\n",
      "Epoch 40/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.9016 - loss: 0.3816 - precision: 0.8608 - recall: 0.8426 - val_accuracy: 0.9019 - val_loss: 0.3301 - val_precision: 0.8464 - val_recall: 0.8632\n",
      "Epoch 41/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8865 - loss: 0.3812 - precision: 0.8310 - recall: 0.8369 - val_accuracy: 0.8933 - val_loss: 0.6249 - val_precision: 0.7980 - val_recall: 0.9117\n",
      "Epoch 42/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8756 - loss: 0.5939 - precision: 0.8164 - recall: 0.8238 - val_accuracy: 0.9067 - val_loss: 0.3076 - val_precision: 0.8524 - val_recall: 0.8718\n",
      "Epoch 43/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8979 - loss: 0.3342 - precision: 0.8515 - recall: 0.8561 - val_accuracy: 0.9086 - val_loss: 0.3509 - val_precision: 0.9381 - val_recall: 0.7778\n",
      "Epoch 44/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.9054 - loss: 0.2994 - precision: 0.8529 - recall: 0.8609 - val_accuracy: 0.8876 - val_loss: 0.3434 - val_precision: 0.7891 - val_recall: 0.9060\n",
      "Epoch 45/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.8913 - loss: 0.3640 - precision: 0.8385 - recall: 0.8320 - val_accuracy: 0.9038 - val_loss: 0.2707 - val_precision: 0.8571 - val_recall: 0.8547\n",
      "Epoch 46/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.8942 - loss: 0.3599 - precision: 0.8347 - recall: 0.8647 - val_accuracy: 0.9000 - val_loss: 0.2619 - val_precision: 0.8203 - val_recall: 0.8974\n",
      "Epoch 47/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.8781 - loss: 0.3696 - precision: 0.8181 - recall: 0.8205 - val_accuracy: 0.8981 - val_loss: 0.2947 - val_precision: 0.8352 - val_recall: 0.8661\n",
      "Epoch 48/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.8802 - loss: 0.5076 - precision: 0.8038 - recall: 0.8336 - val_accuracy: 0.9067 - val_loss: 0.3041 - val_precision: 0.8710 - val_recall: 0.8462\n",
      "Epoch 49/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.8706 - loss: 0.4142 - precision: 0.8048 - recall: 0.8086 - val_accuracy: 0.9019 - val_loss: 0.2761 - val_precision: 0.8464 - val_recall: 0.8632\n",
      "Epoch 50/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8961 - loss: 0.3212 - precision: 0.8493 - recall: 0.8462 - val_accuracy: 0.8895 - val_loss: 0.3536 - val_precision: 0.7859 - val_recall: 0.9202\n",
      "Epoch 51/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.8951 - loss: 0.3232 - precision: 0.8356 - recall: 0.8459 - val_accuracy: 0.9057 - val_loss: 0.2969 - val_precision: 0.8621 - val_recall: 0.8547\n",
      "Epoch 52/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.8628 - loss: 0.2961 - precision: 0.8475 - recall: 0.7356 - val_accuracy: 0.8895 - val_loss: 0.2701 - val_precision: 0.7930 - val_recall: 0.9060\n",
      "Epoch 53/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8554 - loss: 0.2961 - precision: 0.8241 - recall: 0.7401 - val_accuracy: 0.8924 - val_loss: 0.2718 - val_precision: 0.7990 - val_recall: 0.9060\n",
      "Epoch 54/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.8563 - loss: 0.2725 - precision: 0.8545 - recall: 0.6994 - val_accuracy: 0.8229 - val_loss: 0.3490 - val_precision: 0.8802 - val_recall: 0.5442\n",
      "Epoch 55/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8764 - loss: 0.2834 - precision: 0.8403 - recall: 0.7856 - val_accuracy: 0.8981 - val_loss: 0.2848 - val_precision: 0.8315 - val_recall: 0.8718\n",
      "Epoch 56/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.9067 - loss: 0.2646 - precision: 0.8343 - recall: 0.8873 - val_accuracy: 0.8933 - val_loss: 0.2762 - val_precision: 0.8010 - val_recall: 0.9060\n",
      "Epoch 57/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9058 - loss: 0.2601 - precision: 0.8414 - recall: 0.8848 - val_accuracy: 0.8895 - val_loss: 0.2826 - val_precision: 0.7859 - val_recall: 0.9202\n",
      "Epoch 58/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8930 - loss: 0.2787 - precision: 0.8030 - recall: 0.8998 - val_accuracy: 0.9048 - val_loss: 0.2695 - val_precision: 0.8401 - val_recall: 0.8832\n",
      "Epoch 59/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.8999 - loss: 0.2733 - precision: 0.8193 - recall: 0.9038 - val_accuracy: 0.8962 - val_loss: 0.2955 - val_precision: 0.8253 - val_recall: 0.8746\n",
      "Epoch 60/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.8958 - loss: 0.2795 - precision: 0.8255 - recall: 0.8838 - val_accuracy: 0.9086 - val_loss: 0.3017 - val_precision: 0.8875 - val_recall: 0.8319\n",
      "Epoch 61/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.8988 - loss: 0.2812 - precision: 0.8230 - recall: 0.8955 - val_accuracy: 0.8895 - val_loss: 0.3007 - val_precision: 0.7975 - val_recall: 0.8974\n",
      "Epoch 62/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8878 - loss: 0.2854 - precision: 0.7962 - recall: 0.8982 - val_accuracy: 0.9010 - val_loss: 0.2686 - val_precision: 0.8384 - val_recall: 0.8718\n",
      "Epoch 63/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.9079 - loss: 0.2549 - precision: 0.8439 - recall: 0.8979 - val_accuracy: 0.8943 - val_loss: 0.2775 - val_precision: 0.8093 - val_recall: 0.8946\n",
      "Epoch 64/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8910 - loss: 0.2827 - precision: 0.8262 - recall: 0.8643 - val_accuracy: 0.8981 - val_loss: 0.2995 - val_precision: 0.8297 - val_recall: 0.8746\n",
      "Epoch 65/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.8907 - loss: 0.2933 - precision: 0.8116 - recall: 0.8774 - val_accuracy: 0.8943 - val_loss: 0.3139 - val_precision: 0.8191 - val_recall: 0.8775\n",
      "Epoch 66/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9066 - loss: 0.2604 - precision: 0.8356 - recall: 0.8963 - val_accuracy: 0.9048 - val_loss: 0.2862 - val_precision: 0.8555 - val_recall: 0.8604\n",
      "Epoch 67/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8983 - loss: 0.2903 - precision: 0.8254 - recall: 0.8858 - val_accuracy: 0.9048 - val_loss: 0.2978 - val_precision: 0.8515 - val_recall: 0.8661\n",
      "Epoch 68/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.8973 - loss: 0.2802 - precision: 0.8326 - recall: 0.8643 - val_accuracy: 0.8990 - val_loss: 0.2840 - val_precision: 0.8232 - val_recall: 0.8889\n",
      "Epoch 69/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9031 - loss: 0.2543 - precision: 0.8496 - recall: 0.8808 - val_accuracy: 0.9095 - val_loss: 0.2565 - val_precision: 0.8926 - val_recall: 0.8291\n",
      "Epoch 70/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8975 - loss: 0.2739 - precision: 0.8348 - recall: 0.8592 - val_accuracy: 0.9086 - val_loss: 0.2590 - val_precision: 0.8923 - val_recall: 0.8262\n",
      "Epoch 71/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.9033 - loss: 0.2733 - precision: 0.8392 - recall: 0.8949 - val_accuracy: 0.9095 - val_loss: 0.2642 - val_precision: 0.8787 - val_recall: 0.8462\n",
      "Epoch 72/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.9005 - loss: 0.2639 - precision: 0.8497 - recall: 0.8596 - val_accuracy: 0.8810 - val_loss: 0.3190 - val_precision: 0.7665 - val_recall: 0.9259\n",
      "Epoch 73/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9010 - loss: 0.2644 - precision: 0.8454 - recall: 0.8598 - val_accuracy: 0.9095 - val_loss: 0.2769 - val_precision: 0.8765 - val_recall: 0.8490\n",
      "Epoch 74/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.8896 - loss: 0.2792 - precision: 0.8507 - recall: 0.8178 - val_accuracy: 0.8867 - val_loss: 0.3127 - val_precision: 0.7775 - val_recall: 0.9259\n",
      "Epoch 75/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9016 - loss: 0.2609 - precision: 0.8368 - recall: 0.8751 - val_accuracy: 0.8895 - val_loss: 0.3342 - val_precision: 0.7990 - val_recall: 0.8946\n",
      "Epoch 76/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8951 - loss: 0.2777 - precision: 0.8318 - recall: 0.8745 - val_accuracy: 0.8943 - val_loss: 0.2915 - val_precision: 0.8158 - val_recall: 0.8832\n",
      "Epoch 77/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8834 - loss: 0.2991 - precision: 0.8141 - recall: 0.8570 - val_accuracy: 0.9057 - val_loss: 0.2805 - val_precision: 0.8684 - val_recall: 0.8462\n",
      "Epoch 78/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8959 - loss: 0.2807 - precision: 0.8212 - recall: 0.8795 - val_accuracy: 0.8952 - val_loss: 0.3089 - val_precision: 0.8179 - val_recall: 0.8832\n",
      "Epoch 79/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.8898 - loss: 0.2832 - precision: 0.8320 - recall: 0.8461 - val_accuracy: 0.9095 - val_loss: 0.2541 - val_precision: 0.8879 - val_recall: 0.8348\n",
      "Epoch 80/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.8942 - loss: 0.2616 - precision: 0.8386 - recall: 0.8414 - val_accuracy: 0.9086 - val_loss: 0.2618 - val_precision: 0.8923 - val_recall: 0.8262\n",
      "Epoch 81/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.8722 - loss: 0.3365 - precision: 0.7882 - recall: 0.8318 - val_accuracy: 0.8705 - val_loss: 0.3509 - val_precision: 0.9614 - val_recall: 0.6382\n",
      "Epoch 82/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9005 - loss: 0.2839 - precision: 0.8589 - recall: 0.8452 - val_accuracy: 0.9010 - val_loss: 0.2867 - val_precision: 0.8365 - val_recall: 0.8746\n",
      "Epoch 83/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.9003 - loss: 0.2730 - precision: 0.8460 - recall: 0.8790 - val_accuracy: 0.9067 - val_loss: 0.2847 - val_precision: 0.8667 - val_recall: 0.8519\n",
      "Epoch 84/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9086 - loss: 0.2557 - precision: 0.8687 - recall: 0.8660 - val_accuracy: 0.9095 - val_loss: 0.3158 - val_precision: 0.8926 - val_recall: 0.8291\n",
      "Epoch 85/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8908 - loss: 0.2825 - precision: 0.8116 - recall: 0.8681 - val_accuracy: 0.9067 - val_loss: 0.2590 - val_precision: 0.8667 - val_recall: 0.8519\n",
      "Epoch 86/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.8881 - loss: 0.2961 - precision: 0.8292 - recall: 0.8279 - val_accuracy: 0.9086 - val_loss: 0.2571 - val_precision: 0.8875 - val_recall: 0.8319\n",
      "Epoch 87/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.8995 - loss: 0.2739 - precision: 0.8463 - recall: 0.8512 - val_accuracy: 0.9067 - val_loss: 0.3098 - val_precision: 0.8646 - val_recall: 0.8547\n",
      "Epoch 88/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - accuracy: 0.8995 - loss: 0.2681 - precision: 0.8456 - recall: 0.8526 - val_accuracy: 0.9067 - val_loss: 0.2731 - val_precision: 0.8625 - val_recall: 0.8575\n",
      "Epoch 89/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.9081 - loss: 0.2406 - precision: 0.8566 - recall: 0.8713 - val_accuracy: 0.9114 - val_loss: 0.2716 - val_precision: 0.9006 - val_recall: 0.8262\n",
      "Epoch 90/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.8991 - loss: 0.2689 - precision: 0.8528 - recall: 0.8374 - val_accuracy: 0.9038 - val_loss: 0.2880 - val_precision: 0.8551 - val_recall: 0.8575\n",
      "Epoch 91/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.9041 - loss: 0.2585 - precision: 0.8446 - recall: 0.8673 - val_accuracy: 0.9057 - val_loss: 0.2736 - val_precision: 0.8621 - val_recall: 0.8547\n",
      "Epoch 92/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9029 - loss: 0.2630 - precision: 0.8460 - recall: 0.8659 - val_accuracy: 0.9048 - val_loss: 0.2582 - val_precision: 0.8555 - val_recall: 0.8604\n",
      "Epoch 93/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.9121 - loss: 0.2384 - precision: 0.8712 - recall: 0.8723 - val_accuracy: 0.8905 - val_loss: 0.2853 - val_precision: 0.7892 - val_recall: 0.9174\n",
      "Epoch 94/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9047 - loss: 0.2444 - precision: 0.8310 - recall: 0.8927 - val_accuracy: 0.9067 - val_loss: 0.2678 - val_precision: 0.8524 - val_recall: 0.8718\n",
      "Epoch 95/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9154 - loss: 0.2374 - precision: 0.8622 - recall: 0.8682 - val_accuracy: 0.8981 - val_loss: 0.2859 - val_precision: 0.8280 - val_recall: 0.8775\n",
      "Epoch 96/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8989 - loss: 0.2778 - precision: 0.8457 - recall: 0.8580 - val_accuracy: 0.9010 - val_loss: 0.2824 - val_precision: 0.8421 - val_recall: 0.8661\n",
      "Epoch 97/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.8983 - loss: 0.2647 - precision: 0.8459 - recall: 0.8582 - val_accuracy: 0.9010 - val_loss: 0.2844 - val_precision: 0.8365 - val_recall: 0.8746\n",
      "Epoch 98/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.9096 - loss: 0.2379 - precision: 0.8736 - recall: 0.8587 - val_accuracy: 0.9019 - val_loss: 0.2621 - val_precision: 0.8444 - val_recall: 0.8661\n",
      "Epoch 99/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.9077 - loss: 0.2490 - precision: 0.8591 - recall: 0.8608 - val_accuracy: 0.8819 - val_loss: 0.3079 - val_precision: 0.7709 - val_recall: 0.9202\n",
      "Epoch 100/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.8950 - loss: 0.2760 - precision: 0.8100 - recall: 0.8984 - val_accuracy: 0.9219 - val_loss: 0.2544 - val_precision: 0.9439 - val_recall: 0.8148\n",
      "Epoch 101/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8971 - loss: 0.2648 - precision: 0.8326 - recall: 0.8444 - val_accuracy: 0.8981 - val_loss: 0.2931 - val_precision: 0.8352 - val_recall: 0.8661\n",
      "Epoch 102/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.9055 - loss: 0.2552 - precision: 0.8448 - recall: 0.8711 - val_accuracy: 0.9086 - val_loss: 0.2653 - val_precision: 0.8696 - val_recall: 0.8547\n",
      "Epoch 103/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.8997 - loss: 0.2622 - precision: 0.8446 - recall: 0.8636 - val_accuracy: 0.8838 - val_loss: 0.3011 - val_precision: 0.7707 - val_recall: 0.9288\n",
      "Epoch 104/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.8984 - loss: 0.2612 - precision: 0.8284 - recall: 0.8828 - val_accuracy: 0.8867 - val_loss: 0.2993 - val_precision: 0.7816 - val_recall: 0.9174\n",
      "Epoch 105/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9071 - loss: 0.2619 - precision: 0.8540 - recall: 0.8763 - val_accuracy: 0.9105 - val_loss: 0.2460 - val_precision: 0.8768 - val_recall: 0.8519\n",
      "Epoch 106/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.8994 - loss: 0.2595 - precision: 0.8509 - recall: 0.8521 - val_accuracy: 0.9019 - val_loss: 0.2722 - val_precision: 0.8370 - val_recall: 0.8775\n",
      "Epoch 107/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.8895 - loss: 0.2922 - precision: 0.8095 - recall: 0.8750 - val_accuracy: 0.9057 - val_loss: 0.2658 - val_precision: 0.8539 - val_recall: 0.8661\n",
      "Epoch 108/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8897 - loss: 0.2632 - precision: 0.8288 - recall: 0.8459 - val_accuracy: 0.9067 - val_loss: 0.2703 - val_precision: 0.8667 - val_recall: 0.8519\n",
      "Epoch 109/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9025 - loss: 0.2478 - precision: 0.8413 - recall: 0.8588 - val_accuracy: 0.8895 - val_loss: 0.2997 - val_precision: 0.7975 - val_recall: 0.8974\n",
      "Epoch 110/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8999 - loss: 0.2574 - precision: 0.8321 - recall: 0.8835 - val_accuracy: 0.9086 - val_loss: 0.2685 - val_precision: 0.8696 - val_recall: 0.8547\n",
      "Epoch 111/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9066 - loss: 0.2528 - precision: 0.8573 - recall: 0.8721 - val_accuracy: 0.9038 - val_loss: 0.2619 - val_precision: 0.8492 - val_recall: 0.8661\n",
      "Epoch 112/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9013 - loss: 0.2473 - precision: 0.8464 - recall: 0.8519 - val_accuracy: 0.9067 - val_loss: 0.2724 - val_precision: 0.8543 - val_recall: 0.8689\n",
      "Epoch 113/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9039 - loss: 0.2408 - precision: 0.8523 - recall: 0.8616 - val_accuracy: 0.9114 - val_loss: 0.2372 - val_precision: 0.8933 - val_recall: 0.8348\n",
      "Epoch 114/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.9055 - loss: 0.2313 - precision: 0.8642 - recall: 0.8483 - val_accuracy: 0.9114 - val_loss: 0.2675 - val_precision: 0.8933 - val_recall: 0.8348\n",
      "Epoch 115/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.9049 - loss: 0.2491 - precision: 0.8603 - recall: 0.8602 - val_accuracy: 0.9133 - val_loss: 0.2703 - val_precision: 0.9610 - val_recall: 0.7721\n",
      "Epoch 116/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9002 - loss: 0.2502 - precision: 0.8538 - recall: 0.8463 - val_accuracy: 0.9038 - val_loss: 0.2595 - val_precision: 0.8511 - val_recall: 0.8632\n",
      "Epoch 117/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.9050 - loss: 0.2460 - precision: 0.8444 - recall: 0.8821 - val_accuracy: 0.7114 - val_loss: 0.4180 - val_precision: 0.7500 - val_recall: 0.2051\n",
      "Epoch 118/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8801 - loss: 0.2792 - precision: 0.8172 - recall: 0.8326 - val_accuracy: 0.8905 - val_loss: 0.2776 - val_precision: 0.7980 - val_recall: 0.9003\n",
      "Epoch 119/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8937 - loss: 0.2730 - precision: 0.8276 - recall: 0.8639 - val_accuracy: 0.8914 - val_loss: 0.2898 - val_precision: 0.7940 - val_recall: 0.9117\n",
      "Epoch 120/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9048 - loss: 0.2507 - precision: 0.8568 - recall: 0.8549 - val_accuracy: 0.9048 - val_loss: 0.2510 - val_precision: 0.8347 - val_recall: 0.8917\n",
      "Epoch 121/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.8991 - loss: 0.2490 - precision: 0.8429 - recall: 0.8515 - val_accuracy: 0.8943 - val_loss: 0.2546 - val_precision: 0.8175 - val_recall: 0.8803\n",
      "Epoch 122/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.9082 - loss: 0.2427 - precision: 0.8567 - recall: 0.8768 - val_accuracy: 0.9095 - val_loss: 0.2466 - val_precision: 0.8721 - val_recall: 0.8547\n",
      "Epoch 123/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.9068 - loss: 0.2578 - precision: 0.8654 - recall: 0.8661 - val_accuracy: 0.9086 - val_loss: 0.2766 - val_precision: 0.8696 - val_recall: 0.8547\n",
      "Epoch 124/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9015 - loss: 0.2494 - precision: 0.8536 - recall: 0.8565 - val_accuracy: 0.8924 - val_loss: 0.2825 - val_precision: 0.8115 - val_recall: 0.8832\n",
      "Epoch 125/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.9036 - loss: 0.2552 - precision: 0.8446 - recall: 0.8700 - val_accuracy: 0.8943 - val_loss: 0.2596 - val_precision: 0.8175 - val_recall: 0.8803\n",
      "Epoch 126/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.8964 - loss: 0.2481 - precision: 0.8359 - recall: 0.8690 - val_accuracy: 0.9114 - val_loss: 0.2562 - val_precision: 0.9243 - val_recall: 0.8006\n",
      "Epoch 127/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.9133 - loss: 0.2441 - precision: 0.8725 - recall: 0.8714 - val_accuracy: 0.8962 - val_loss: 0.2400 - val_precision: 0.8235 - val_recall: 0.8775\n",
      "Epoch 128/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.8988 - loss: 0.2473 - precision: 0.8535 - recall: 0.8505 - val_accuracy: 0.9114 - val_loss: 0.2698 - val_precision: 0.8772 - val_recall: 0.8547\n",
      "Epoch 129/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.9114 - loss: 0.2207 - precision: 0.8684 - recall: 0.8695 - val_accuracy: 0.9095 - val_loss: 0.2717 - val_precision: 0.8879 - val_recall: 0.8348\n",
      "Epoch 130/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.9082 - loss: 0.2361 - precision: 0.8523 - recall: 0.8680 - val_accuracy: 0.9000 - val_loss: 0.2627 - val_precision: 0.8379 - val_recall: 0.8689\n",
      "Epoch 131/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.9093 - loss: 0.2314 - precision: 0.8806 - recall: 0.8481 - val_accuracy: 0.9124 - val_loss: 0.2720 - val_precision: 0.8912 - val_recall: 0.8405\n",
      "Epoch 132/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.8956 - loss: 0.2628 - precision: 0.8464 - recall: 0.8416 - val_accuracy: 0.9076 - val_loss: 0.2555 - val_precision: 0.8848 - val_recall: 0.8319\n",
      "Epoch 133/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.9025 - loss: 0.2444 - precision: 0.8473 - recall: 0.8509 - val_accuracy: 0.9029 - val_loss: 0.2646 - val_precision: 0.8449 - val_recall: 0.8689\n",
      "Epoch 134/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.9071 - loss: 0.2410 - precision: 0.8642 - recall: 0.8589 - val_accuracy: 0.9067 - val_loss: 0.2411 - val_precision: 0.8604 - val_recall: 0.8604\n",
      "Epoch 135/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.9109 - loss: 0.2196 - precision: 0.8564 - recall: 0.8695 - val_accuracy: 0.9114 - val_loss: 0.2385 - val_precision: 0.8933 - val_recall: 0.8348\n",
      "Epoch 136/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9047 - loss: 0.2254 - precision: 0.8557 - recall: 0.8567 - val_accuracy: 0.9152 - val_loss: 0.2318 - val_precision: 0.9018 - val_recall: 0.8376\n",
      "Epoch 137/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.9026 - loss: 0.2455 - precision: 0.8758 - recall: 0.8323 - val_accuracy: 0.9238 - val_loss: 0.2257 - val_precision: 0.9195 - val_recall: 0.8462\n",
      "Epoch 138/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.9046 - loss: 0.2399 - precision: 0.8521 - recall: 0.8593 - val_accuracy: 0.9124 - val_loss: 0.2462 - val_precision: 0.8689 - val_recall: 0.8689\n",
      "Epoch 139/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.8936 - loss: 0.2513 - precision: 0.8374 - recall: 0.8485 - val_accuracy: 0.8943 - val_loss: 0.2471 - val_precision: 0.8209 - val_recall: 0.8746\n",
      "Epoch 140/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.8987 - loss: 0.2430 - precision: 0.8349 - recall: 0.8697 - val_accuracy: 0.9076 - val_loss: 0.2281 - val_precision: 0.8629 - val_recall: 0.8604\n",
      "Epoch 141/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.9051 - loss: 0.2320 - precision: 0.8741 - recall: 0.8438 - val_accuracy: 0.9200 - val_loss: 0.2266 - val_precision: 0.9320 - val_recall: 0.8205\n",
      "Epoch 142/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.9131 - loss: 0.2396 - precision: 0.8889 - recall: 0.8475 - val_accuracy: 0.9105 - val_loss: 0.2231 - val_precision: 0.8813 - val_recall: 0.8462\n",
      "Epoch 143/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.8946 - loss: 0.2450 - precision: 0.8494 - recall: 0.8326 - val_accuracy: 0.9076 - val_loss: 0.2259 - val_precision: 0.8629 - val_recall: 0.8604\n",
      "Epoch 144/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9160 - loss: 0.2164 - precision: 0.8738 - recall: 0.8753 - val_accuracy: 0.8924 - val_loss: 0.2531 - val_precision: 0.8132 - val_recall: 0.8803\n",
      "Epoch 145/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.9104 - loss: 0.2409 - precision: 0.8715 - recall: 0.8686 - val_accuracy: 0.9114 - val_loss: 0.2600 - val_precision: 0.8957 - val_recall: 0.8319\n",
      "Epoch 146/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.9107 - loss: 0.2417 - precision: 0.8788 - recall: 0.8504 - val_accuracy: 0.8952 - val_loss: 0.2459 - val_precision: 0.8266 - val_recall: 0.8689\n",
      "Epoch 147/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9020 - loss: 0.2471 - precision: 0.8784 - recall: 0.8240 - val_accuracy: 0.9076 - val_loss: 0.2475 - val_precision: 0.8671 - val_recall: 0.8547\n",
      "Epoch 148/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9137 - loss: 0.2285 - precision: 0.8873 - recall: 0.8578 - val_accuracy: 0.9029 - val_loss: 0.2670 - val_precision: 0.8507 - val_recall: 0.8604\n",
      "Epoch 149/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9104 - loss: 0.2328 - precision: 0.8606 - recall: 0.8714 - val_accuracy: 0.9200 - val_loss: 0.2237 - val_precision: 0.9293 - val_recall: 0.8234\n",
      "Epoch 150/150\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.9116 - loss: 0.2303 - precision: 0.8978 - recall: 0.8340 - val_accuracy: 0.9162 - val_loss: 0.2421 - val_precision: 0.9175 - val_recall: 0.8234\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=150, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84da6cc14f39d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:52:00.283397Z",
     "start_time": "2024-05-15T17:52:00.242099Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.9212 - loss: 0.2163 - precision: 0.9322 - recall: 0.8373\n",
      "Accuracy: 0.9173333048820496, Precision: 0.9238505959510803, Recall: 0.8286082744598389\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall = model.evaluate(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea073c31bfb7d069",
   "metadata": {},
   "source": [
    "### Get Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "782c913ec4328a23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:52:00.350465Z",
     "start_time": "2024-05-15T17:52:00.283035Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred_classes = (y_pred_prob > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "577667e186c5e002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T17:52:00.356729Z",
     "start_time": "2024-05-15T17:52:00.350957Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Neural Network:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.96      0.94      1474\n",
      "        True       0.92      0.83      0.87       776\n",
      "\n",
      "    accuracy                           0.92      2250\n",
      "   macro avg       0.92      0.90      0.91      2250\n",
      "weighted avg       0.92      0.92      0.92      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred_classes, target_names=['False', 'True'])  # Adjust target names based on your classes\n",
    "print(\"Classification Report Neural Network:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39108bdc-5bca-4935-a11d-393e4e213e21",
   "metadata": {},
   "source": [
    "The neural network achieved strong overall performance, with an accuracy of 92%. It performed well, with a precision of 92%  for the positive class (\"True\"). While the recall for the positive class is slightly lower (83%), the model still demonstrates a strong ability to identify interested homeowners while minimizing false positives. Compared to the other models, the neural network offers high predictive power but at the cost of reduced interpretability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
